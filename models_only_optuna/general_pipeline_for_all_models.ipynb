{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-06T18:06:04.500778Z",
     "start_time": "2024-12-06T18:06:00.321582Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, roc_curve, precision_recall_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from catboost import CatBoostClassifier\n",
    "import pickle\n",
    "from sklearn.inspection import permutation_importance\n",
    "import joblib\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:06:04.563436Z",
     "start_time": "2024-12-06T18:06:04.501779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "marketing_df = pd.read_csv('../3. data_after_txt_proc/bank_marketing_data_after_txt_proc.csv')\n",
    "personal_df = pd.read_csv('../3. data_after_txt_proc/Bank_Personal_Loan_Modelling_after_txt_proc.csv')"
   ],
   "id": "a345226e6e29adcd",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:06:04.610447Z",
     "start_time": "2024-12-06T18:06:04.564437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ModelPipeline:\n",
    "    def __init__(self, data, target_column, test_size=0.2, random_state=42, save_dir='results'):\n",
    "        \"\"\"\n",
    "        Инициализация класса.\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.target_column = target_column\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "        self.save_dir = save_dir\n",
    "\n",
    "        self.X = self.data.drop(columns=[self.target_column])\n",
    "        self.y = self.data[self.target_column]\n",
    "        self.feature_names = self.X.columns.tolist()\n",
    "\n",
    "        # Разделение на обучающие и тестовые данные\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            self.X, self.y, test_size=self.test_size, random_state=self.random_state\n",
    "        )\n",
    "\n",
    "        # Стандартизация данных\n",
    "        self.scaler = StandardScaler()\n",
    "        self.X_train_scaled = self.scaler.fit_transform(self.X_train)\n",
    "        self.X_test_scaled = self.scaler.transform(self.X_test)\n",
    "\n",
    "        # Словарь для хранения моделей\n",
    "        self.models = {\n",
    "            \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=self.random_state),\n",
    "            \"SVM\": SVC(kernel='rbf', C=1, gamma='scale', random_state=self.random_state),\n",
    "            \"Random Forest\": RandomForestClassifier(n_estimators=1000, random_state=self.random_state),\n",
    "            \"Boosting\": None  # Будет заполняться через подбор гиперпараметров с Optuna\n",
    "        }\n",
    "        '''self.models = {\n",
    "            \"Boosting\": None  # Будет заполняться через подбор гиперпараметров с Optuna\n",
    "        }'''\n",
    "\n",
    "    def save_metrics_and_plots(self, metrics, model_name, importances):\n",
    "        \"\"\"\n",
    "        Сохраняет метрики и графики важности признаков в отдельную директорию.\n",
    "        \"\"\"\n",
    "        # Создание директории для сохранения результатов, если она не существует\n",
    "        dataset_dir = os.path.join(self.save_dir, f\"{self.target_column}\")\n",
    "        if not os.path.exists(dataset_dir):\n",
    "            os.makedirs(dataset_dir)\n",
    "    \n",
    "        # Создание директории для модели\n",
    "        model_dir = os.path.join(dataset_dir, model_name)\n",
    "        if not os.path.exists(model_dir):\n",
    "            os.makedirs(model_dir)\n",
    "    \n",
    "        # Сохранение метрик в текстовый файл\n",
    "        metrics_file = os.path.join(model_dir, f\"{model_name}_metrics.txt\")\n",
    "        with open(metrics_file, \"w\") as f:\n",
    "            for metric, value in metrics.items():\n",
    "                f.write(f\"{metric}: {value:.4f}\\n\")\n",
    "    \n",
    "        # Сохранение графика и списка важности признаков, если она есть\n",
    "        if importances is not None:\n",
    "            feature_importance_file = os.path.join(model_dir, f\"{model_name}_feature_importance.txt\")\n",
    "            with open(feature_importance_file, \"w\") as f:\n",
    "                sorted_indices = importances.argsort()[::-1]\n",
    "                for idx in sorted_indices:\n",
    "                    f.write(f\"{self.feature_names[idx]}: {importances[idx]:.4f}\\n\")\n",
    "    \n",
    "            # Сохранение графика важности признаков\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sorted_importances = importances[sorted_indices]\n",
    "            sorted_features = [self.feature_names[i] for i in sorted_indices]\n",
    "            plt.barh(sorted_features, sorted_importances, color='skyblue')\n",
    "            plt.title(f\"Feature Importance ({model_name})\")\n",
    "            plt.xlabel(\"Importance\")\n",
    "            plt.ylabel(\"Features\")\n",
    "            plt.tight_layout()\n",
    "    \n",
    "            plot_file = os.path.join(model_dir, f\"{model_name}_feature_importance.png\")\n",
    "            plt.savefig(plot_file)\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "    def calculate_metrics(self, y_pred, y_pred_proba):\n",
    "        \"\"\"\n",
    "        Рассчитывает метрики модели.\n",
    "        \"\"\"\n",
    "        metrics = {\n",
    "            'accuracy': accuracy_score(self.y_test, y_pred),\n",
    "            'f1': f1_score(self.y_test, y_pred),\n",
    "            'precision': precision_score(self.y_test, y_pred),\n",
    "            'recall': recall_score(self.y_test, y_pred),\n",
    "        }\n",
    "        if y_pred_proba is not None:  # Проверяем доступность вероятностей\n",
    "            metrics['roc_auc'] = roc_auc_score(self.y_test, y_pred_proba)\n",
    "        return metrics\n",
    "\n",
    "    def train_and_evaluate_model(self, model_name, model):\n",
    "        \"\"\"\n",
    "        Обучает модель и вычисляет её метрики.\n",
    "        \"\"\"\n",
    "        print(f\"Training {model_name}...\")\n",
    "        model.fit(self.X_train_scaled, self.y_train)\n",
    "        print(f\"Model {model_name} trained. Evaluating...\")\n",
    "    \n",
    "        y_pred = model.predict(self.X_test_scaled)\n",
    "        y_pred_proba = None\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            print(f\"Using predict_proba for {model_name}...\")\n",
    "            y_pred_proba = model.predict_proba(self.X_test_scaled)[:, 1]\n",
    "        elif hasattr(model, \"decision_function\"):\n",
    "            print(f\"Using decision_function for {model_name}...\")\n",
    "            y_pred_proba = model.decision_function(self.X_test_scaled)\n",
    "    \n",
    "        model_metrics = self.calculate_metrics(y_pred, y_pred_proba)\n",
    "        print(f\"Metrics calculated for {model_name}. Saving results...\")\n",
    "    \n",
    "        importances = None\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            print(f\"Extracting feature importance for {model_name}...\")\n",
    "            importances = model.feature_importances_\n",
    "        elif hasattr(model, 'get_feature_importance'):\n",
    "            importances = model.get_feature_importance()\n",
    "        else:\n",
    "            print(f\"Calculating permutation importance for {model_name}...\")\n",
    "            perm_importance = permutation_importance(\n",
    "                model, self.X_test_scaled, self.y_test, n_repeats=10, random_state=self.random_state\n",
    "            )\n",
    "            importances = perm_importance.importances_mean\n",
    "    \n",
    "        self.save_metrics_and_plots(model_metrics, model_name, importances)\n",
    "        print(f\"Results saved for {model_name}.\")\n",
    "        return model_metrics\n",
    "\n",
    "\n",
    "\n",
    "    def objective_logreg(self, trial):\n",
    "        \"\"\"\n",
    "        Определяет гиперпараметры для Logistic Regression через Optuna.\n",
    "        \"\"\"\n",
    "        C = trial.suggest_float('C', 1e-5, 1e2, log=True)\n",
    "        model = LogisticRegression(max_iter=2000, C=C, random_state=self.random_state)\n",
    "\n",
    "        score = cross_val_score(model, self.X_train_scaled, self.y_train, cv=5, scoring='f1').mean()\n",
    "        return score\n",
    "\n",
    "    def objective_svm(self, trial):\n",
    "        \"\"\"\n",
    "        Определяет гиперпараметры для SVM через Optuna.\n",
    "        \"\"\"\n",
    "        C = trial.suggest_float('C', 1e-5, 1e2, log=True)\n",
    "        kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "        gamma = None\n",
    "        degree = None\n",
    "        if kernel in ['rbf', 'poly', 'sigmoid']:\n",
    "            gamma = trial.suggest_float('gamma', 1e-5, 1e1, log=True)\n",
    "        if kernel == 'poly':\n",
    "            degree = trial.suggest_int('degree', 2, 5)\n",
    "\n",
    "        model_m = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('clf', SVC(\n",
    "                C=C,\n",
    "                kernel=kernel,\n",
    "                gamma=gamma if kernel in ['rbf', 'poly', 'sigmoid'] else 'scale',\n",
    "                degree=degree if kernel == 'poly' else 3,\n",
    "                random_state=42,\n",
    "            ))\n",
    "        ])\n",
    "\n",
    "        score = cross_val_score(model_m, self.X_train_scaled, self.y_train, cv=5, scoring='f1').mean()\n",
    "        return score\n",
    "\n",
    "    def objective_rf(self, trial):\n",
    "        \"\"\"\n",
    "        Определяет гиперпараметры для Random Forest через Optuna.\n",
    "        \"\"\"\n",
    "        n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
    "        max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
    "        min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "        min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "        max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\n",
    "\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            max_features=max_features,\n",
    "            random_state=42\n",
    "        )\n",
    "        score = cross_val_score(model, self.X_train_scaled, self.y_train, cv=5, scoring='f1').mean()\n",
    "        return score\n",
    "\n",
    "    def objective_boosting(self, trial):\n",
    "        \"\"\"\n",
    "        Определяет гиперпараметры для Boosting через Optuna.\n",
    "        \"\"\"\n",
    "        learning_rate = trial.suggest_float('learning_rate', 1e-3, 1e-1, log=True)\n",
    "        depth = trial.suggest_int('depth', 4, 12)\n",
    "        iterations = trial.suggest_int('iterations', 100, 2000, step=25)\n",
    "\n",
    "        model = CatBoostClassifier(\n",
    "            task_type='GPU',  # Для использования GPU\n",
    "            iterations=iterations,\n",
    "            depth=depth,\n",
    "            learning_rate=learning_rate,\n",
    "            loss_function='Logloss',\n",
    "            random_seed=self.random_state,\n",
    "            logging_level='Silent'\n",
    "        )\n",
    "\n",
    "        score = cross_val_score(model, self.X_train_scaled, self.y_train, cv=5, scoring='f1').mean()\n",
    "        return score\n",
    "    \n",
    "    def initialize_directories(self, model_name):\n",
    "        \"\"\"\n",
    "        Создаёт структуру директорий для сохранения результатов.\n",
    "        \"\"\"\n",
    "        # Создание базовой директории\n",
    "        dataset_dir = os.path.join(self.save_dir, f\"{self.target_column}\")\n",
    "        if not os.path.exists(dataset_dir):\n",
    "            os.makedirs(dataset_dir)\n",
    "    \n",
    "        # Директория для текущей модели\n",
    "        model_dir = os.path.join(dataset_dir, model_name)\n",
    "        if not os.path.exists(model_dir):\n",
    "            os.makedirs(model_dir)\n",
    "    \n",
    "        return model_dir\n",
    "    def save_model(self, model, model_name):\n",
    "        \"\"\"\n",
    "        Сохраняет обученную модель в соответствующую директорию.\n",
    "        \"\"\"\n",
    "        model_dir = self.initialize_directories(model_name)\n",
    "        model_path = os.path.join(model_dir, f\"{model_name}_model.pkl\")\n",
    "    \n",
    "        with open(model_path, 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "        print(f\"Model {model_name} saved to {model_path}.\")\n",
    "    def load_model(self, model_name):\n",
    "        \"\"\"\n",
    "        Загружает модель из соответствующей директории.\n",
    "        \"\"\"\n",
    "        model_dir = self.initialize_directories(model_name)\n",
    "        model_path = os.path.join(model_dir, f\"{model_name}_model.pkl\")\n",
    "    \n",
    "        if os.path.exists(model_path):\n",
    "            with open(model_path, 'rb') as f:\n",
    "                model = pickle.load(f)\n",
    "            print(f\"Model {model_name} loaded from {model_path}.\")\n",
    "            return model\n",
    "        else:\n",
    "            print(f\"No saved model found for {model_name} in {model_dir}.\")\n",
    "            return None\n",
    "\n",
    "    def optimize_model(self, model_name):\n",
    "        \"\"\"\n",
    "        Запускает Optuna для поиска лучших гиперпараметров.\n",
    "        \"\"\"\n",
    "        print(f\"Starting optimization for {model_name}...\")\n",
    "        def objective(trial):\n",
    "            if model_name == \"Logistic Regression\":\n",
    "                return self.objective_logreg(trial)\n",
    "            elif model_name == \"SVM\":\n",
    "                return self.objective_svm(trial)\n",
    "            elif model_name == \"Random Forest\":\n",
    "                return self.objective_rf(trial)\n",
    "            elif model_name == \"Boosting\":\n",
    "                return self.objective_boosting(trial)\n",
    "    \n",
    "        # Убираем joblib.parallel_backend для предотвращения проблем\n",
    "        study = optuna.create_study(direction='maximize')\n",
    "        study.optimize(objective, n_trials=50)  # Без параллелизации\n",
    "    \n",
    "        best_params = study.best_params\n",
    "        print(f\"Optimization completed for {model_name}. Best parameters: {best_params}\")\n",
    "    \n",
    "        # Создание модели с лучшими параметрами\n",
    "        if model_name == \"Logistic Regression\":\n",
    "            return LogisticRegression(max_iter=1000, C=best_params['C'], random_state=self.random_state)\n",
    "        elif model_name == \"SVM\":\n",
    "            return SVC(\n",
    "                C=best_params['C'],\n",
    "                kernel=best_params['kernel'],\n",
    "                gamma=best_params.get('gamma', 'scale'),\n",
    "                random_state=self.random_state\n",
    "            )\n",
    "        elif model_name == \"Random Forest\":\n",
    "            return RandomForestClassifier(\n",
    "                n_estimators=best_params['n_estimators'],\n",
    "                max_depth=best_params['max_depth'],\n",
    "                min_samples_split=best_params['min_samples_split'],\n",
    "                min_samples_leaf=best_params['min_samples_leaf'],\n",
    "                random_state=self.random_state\n",
    "            )\n",
    "        elif model_name == \"Boosting\":\n",
    "            return CatBoostClassifier(\n",
    "                task_type='GPU',\n",
    "                iterations=best_params['iterations'],\n",
    "                depth=best_params['depth'],\n",
    "                learning_rate=best_params['learning_rate'],\n",
    "                loss_function='Logloss',\n",
    "                random_seed=self.random_state,\n",
    "                logging_level='Silent'\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def run_pipeline(self):\n",
    "        \"\"\"\n",
    "        Полный запуск конвейера: оптимизация гиперпараметров, обучение и оценка моделей.\n",
    "        \"\"\"\n",
    "        def process_model(model_name):\n",
    "            print(f\"\\nProcessing {model_name}...\")\n",
    "            optimized_model = self.optimize_model(model_name)\n",
    "            print(f\"Optimization completed for {model_name}. Training...\")\n",
    "            metrics = self.train_and_evaluate_model(model_name, optimized_model)\n",
    "            self.save_model(optimized_model, model_name)\n",
    "            print(f\"Finished processing {model_name}. Metrics: {metrics}\")\n",
    "\n",
    "        print(\"Starting the pipeline...\")\n",
    "        for model_name in tqdm(self.models.keys(), desc=\"Models\"):\n",
    "            process_model(model_name)\n",
    "        print(\"Pipeline completed.\")\n",
    "\n",
    "\n",
    "    def save_metric_plots(self, model_name, y_true, y_pred_proba):\n",
    "        \"\"\"\n",
    "        Сохраняет графики, такие как ROC-кривая и Precision-Recall.\n",
    "        \"\"\"\n",
    "        model_dir = self.initialize_directories(model_name)\n",
    "    \n",
    "        # ROC-кривая\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(fpr, tpr, label=\"ROC Curve\")\n",
    "        plt.title(f\"ROC Curve for {model_name}\")\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        roc_path = os.path.join(model_dir, \"roc_curve.png\")\n",
    "        plt.savefig(roc_path)\n",
    "        plt.close()\n",
    "    \n",
    "        # Precision-Recall кривая\n",
    "        precision, recall, _ = precision_recall_curve(y_true, y_pred_proba)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(recall, precision, label=\"Precision-Recall Curve\")\n",
    "        plt.title(f\"Precision-Recall Curve for {model_name}\")\n",
    "        plt.xlabel(\"Recall\")\n",
    "        plt.ylabel(\"Precision\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        pr_path = os.path.join(model_dir, \"precision_recall_curve.png\")\n",
    "        plt.savefig(pr_path)\n",
    "        plt.close()\n",
    "    \n",
    "        print(f\"Metric plots saved for {model_name} in {model_dir}.\")\n"
   ],
   "id": "121b75917a93adfc",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T20:09:01.341323Z",
     "start_time": "2024-12-06T20:09:00.732554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "marketing_pipeline = ModelPipeline(data=marketing_df, target_column='deposit', test_size=0.2, random_state=42, save_dir='../pipelines/marketing_df')\n",
    "marketing_pipeline.run_pipeline()"
   ],
   "id": "fd34b898644c0ef5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models:   0%|          | 0/4 [00:00<?, ?it/s][I 2024-12-06 23:09:00,771] A new study created in memory with name: no-name-fe687835-fcde-4889-953b-8ca6794606c3\n",
      "[W 2024-12-06 23:09:00,879] Trial 0 failed with parameters: {'C': 4.736980677163974} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mitay\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "FileNotFoundError: [WinError 3] Системе не удается найти указанный путь: '/dev/shm'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mitay\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py\", line 261, in objective\n",
      "    return self.objective_logreg(trial)\n",
      "  File \"C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py\", line 140, in objective_logreg\n",
      "    score = cross_val_score(model, self.X_train_scaled, self.y_train, cv=5, scoring='f1').mean()\n",
      "  File \"C:\\Users\\mitay\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 562, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "  File \"C:\\Users\\mitay\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 214, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mitay\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 309, in cross_validate\n",
      "    results = parallel(\n",
      "  File \"C:\\Users\\mitay\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 65, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"C:\\Users\\mitay\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\site-packages\\joblib\\parallel.py\", line 1909, in __call__\n",
      "    n_jobs = self._initialize_backend()\n",
      "  File \"C:\\Users\\mitay\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\site-packages\\joblib\\parallel.py\", line 1359, in _initialize_backend\n",
      "    n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,\n",
      "  File \"C:\\Users\\mitay\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 514, in configure\n",
      "    self._pool = MemmappingPool(n_jobs, **memmappingpool_args)\n",
      "  File \"C:\\Users\\mitay\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\site-packages\\joblib\\pool.py\", line 303, in __init__\n",
      "    manager = TemporaryResourcesManager(temp_folder)\n",
      "  File \"C:\\Users\\mitay\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\site-packages\\joblib\\_memmapping_reducer.py\", line 540, in __init__\n",
      "    self.set_current_context(context_id)\n",
      "  File \"C:\\Users\\mitay\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\site-packages\\joblib\\_memmapping_reducer.py\", line 544, in set_current_context\n",
      "    self.register_new_context(context_id)\n",
      "  File \"C:\\Users\\mitay\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\site-packages\\joblib\\_memmapping_reducer.py\", line 566, in register_new_context\n",
      "    new_folder_path, _ = _get_temp_dir(\n",
      "  File \"C:\\Users\\mitay\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\site-packages\\joblib\\_memmapping_reducer.py\", line 206, in _get_temp_dir\n",
      "    if os.path.exists(SYSTEM_SHARED_MEM_FS) and hasattr(os, 'statvfs'):\n",
      "  File \"C:\\Users\\mitay\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n",
      "[W 2024-12-06 23:09:00,907] Trial 0 failed with value None.\n",
      "Models:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Logistic Regression...\n",
      "Starting optimization for Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\genericpath.py:19\u001B[0m, in \u001B[0;36mexists\u001B[1;34m(path)\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 19\u001B[0m     \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mOSError\u001B[39;00m, \u001B[38;5;167;01mValueError\u001B[39;00m):\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [WinError 3] Системе не удается найти указанный путь: '/dev/shm'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[1;32m<timed exec>:2\u001B[0m\n",
      "Cell \u001B[1;32mIn[3], line 329\u001B[0m, in \u001B[0;36mModelPipeline.run_pipeline\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    327\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mStarting the pipeline...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    328\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m model_name \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodels\u001B[38;5;241m.\u001B[39mkeys(), desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModels\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m--> 329\u001B[0m     \u001B[43mprocess_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    330\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPipeline completed.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[3], line 321\u001B[0m, in \u001B[0;36mModelPipeline.run_pipeline.<locals>.process_model\u001B[1;34m(model_name)\u001B[0m\n\u001B[0;32m    319\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mprocess_model\u001B[39m(model_name):\n\u001B[0;32m    320\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mProcessing \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 321\u001B[0m     optimized_model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimize_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    322\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOptimization completed for \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. Training...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    323\u001B[0m     metrics \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_and_evaluate_model(model_name, optimized_model)\n",
      "Cell \u001B[1;32mIn[3], line 278\u001B[0m, in \u001B[0;36mModelPipeline.optimize_model\u001B[1;34m(self, model_name, n_trials)\u001B[0m\n\u001B[0;32m    275\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    276\u001B[0m     \u001B[38;5;66;03m# Используем многопоточность для других моделей\u001B[39;00m\n\u001B[0;32m    277\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m joblib\u001B[38;5;241m.\u001B[39mparallel_backend(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmultiprocessing\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m--> 278\u001B[0m         \u001B[43mstudy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobjective\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_trials\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    280\u001B[0m best_params \u001B[38;5;241m=\u001B[39m study\u001B[38;5;241m.\u001B[39mbest_params\n\u001B[0;32m    281\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOptimization completed for \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. Best parameters: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbest_params\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\site-packages\\optuna\\study\\study.py:475\u001B[0m, in \u001B[0;36mStudy.optimize\u001B[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m    373\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21moptimize\u001B[39m(\n\u001B[0;32m    374\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    375\u001B[0m     func: ObjectiveFuncType,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    382\u001B[0m     show_progress_bar: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    383\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    384\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Optimize an objective function.\u001B[39;00m\n\u001B[0;32m    385\u001B[0m \n\u001B[0;32m    386\u001B[0m \u001B[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    473\u001B[0m \u001B[38;5;124;03m            If nested invocation of this method occurs.\u001B[39;00m\n\u001B[0;32m    474\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 475\u001B[0m     \u001B[43m_optimize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    476\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstudy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    477\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    478\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    479\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    480\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    481\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mtuple\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mIterable\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    482\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    483\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    484\u001B[0m \u001B[43m        \u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshow_progress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    485\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\site-packages\\optuna\\study\\_optimize.py:63\u001B[0m, in \u001B[0;36m_optimize\u001B[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m     61\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     62\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m---> 63\u001B[0m         \u001B[43m_optimize_sequential\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     64\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     65\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     66\u001B[0m \u001B[43m            \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     67\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     68\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     69\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     70\u001B[0m \u001B[43m            \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     71\u001B[0m \u001B[43m            \u001B[49m\u001B[43mreseed_sampler_rng\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     72\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtime_start\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     73\u001B[0m \u001B[43m            \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprogress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     74\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     75\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     76\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\site-packages\\optuna\\study\\_optimize.py:160\u001B[0m, in \u001B[0;36m_optimize_sequential\u001B[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001B[0m\n\u001B[0;32m    157\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m    159\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 160\u001B[0m     frozen_trial \u001B[38;5;241m=\u001B[39m \u001B[43m_run_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    161\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    162\u001B[0m     \u001B[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001B[39;00m\n\u001B[0;32m    163\u001B[0m     \u001B[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001B[39;00m\n\u001B[0;32m    164\u001B[0m     \u001B[38;5;66;03m# Please refer to the following PR for further details:\u001B[39;00m\n\u001B[0;32m    165\u001B[0m     \u001B[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001B[39;00m\n\u001B[0;32m    166\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m gc_after_trial:\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\site-packages\\optuna\\study\\_optimize.py:248\u001B[0m, in \u001B[0;36m_run_trial\u001B[1;34m(study, func, catch)\u001B[0m\n\u001B[0;32m    241\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mShould not reach.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    243\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    244\u001B[0m     frozen_trial\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m==\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mFAIL\n\u001B[0;32m    245\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m func_err \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    246\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(func_err, catch)\n\u001B[0;32m    247\u001B[0m ):\n\u001B[1;32m--> 248\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m func_err\n\u001B[0;32m    249\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m frozen_trial\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\site-packages\\optuna\\study\\_optimize.py:197\u001B[0m, in \u001B[0;36m_run_trial\u001B[1;34m(study, func, catch)\u001B[0m\n\u001B[0;32m    195\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m get_heartbeat_thread(trial\u001B[38;5;241m.\u001B[39m_trial_id, study\u001B[38;5;241m.\u001B[39m_storage):\n\u001B[0;32m    196\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 197\u001B[0m         value_or_values \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    198\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m exceptions\u001B[38;5;241m.\u001B[39mTrialPruned \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    199\u001B[0m         \u001B[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001B[39;00m\n\u001B[0;32m    200\u001B[0m         state \u001B[38;5;241m=\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mPRUNED\n",
      "Cell \u001B[1;32mIn[3], line 261\u001B[0m, in \u001B[0;36mModelPipeline.optimize_model.<locals>.objective\u001B[1;34m(trial)\u001B[0m\n\u001B[0;32m    259\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mobjective\u001B[39m(trial):\n\u001B[0;32m    260\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m model_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLogistic Regression\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 261\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mobjective_logreg\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    262\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m model_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSVM\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    263\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobjective_svm(trial)\n",
      "Cell \u001B[1;32mIn[3], line 140\u001B[0m, in \u001B[0;36mModelPipeline.objective_logreg\u001B[1;34m(self, trial)\u001B[0m\n\u001B[0;32m    137\u001B[0m C \u001B[38;5;241m=\u001B[39m trial\u001B[38;5;241m.\u001B[39msuggest_float(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mC\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m1e-5\u001B[39m, \u001B[38;5;241m1e2\u001B[39m, log\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    138\u001B[0m model \u001B[38;5;241m=\u001B[39m LogisticRegression(max_iter\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2000\u001B[39m, C\u001B[38;5;241m=\u001B[39mC, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrandom_state)\n\u001B[1;32m--> 140\u001B[0m score \u001B[38;5;241m=\u001B[39m \u001B[43mcross_val_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mX_train_scaled\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscoring\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mf1\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mmean()\n\u001B[0;32m    141\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m score\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:562\u001B[0m, in \u001B[0;36mcross_val_score\u001B[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001B[0m\n\u001B[0;32m    559\u001B[0m \u001B[38;5;66;03m# To ensure multimetric format is not supported\u001B[39;00m\n\u001B[0;32m    560\u001B[0m scorer \u001B[38;5;241m=\u001B[39m check_scoring(estimator, scoring\u001B[38;5;241m=\u001B[39mscoring)\n\u001B[1;32m--> 562\u001B[0m cv_results \u001B[38;5;241m=\u001B[39m \u001B[43mcross_validate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    563\u001B[0m \u001B[43m    \u001B[49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    564\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    565\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    566\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgroups\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    567\u001B[0m \u001B[43m    \u001B[49m\u001B[43mscoring\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mscore\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mscorer\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    568\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    569\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    570\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    571\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfit_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    572\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpre_dispatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpre_dispatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    573\u001B[0m \u001B[43m    \u001B[49m\u001B[43merror_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merror_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    574\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    575\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m cv_results[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_score\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    208\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    209\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m    210\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m    211\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m    212\u001B[0m         )\n\u001B[0;32m    213\u001B[0m     ):\n\u001B[1;32m--> 214\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    215\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[0;32m    217\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[0;32m    218\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[0;32m    219\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[0;32m    220\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[0;32m    221\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    222\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    223\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[0;32m    224\u001B[0m     )\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:309\u001B[0m, in \u001B[0;36mcross_validate\u001B[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001B[0m\n\u001B[0;32m    306\u001B[0m \u001B[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001B[39;00m\n\u001B[0;32m    307\u001B[0m \u001B[38;5;66;03m# independent, and that it is pickle-able.\u001B[39;00m\n\u001B[0;32m    308\u001B[0m parallel \u001B[38;5;241m=\u001B[39m Parallel(n_jobs\u001B[38;5;241m=\u001B[39mn_jobs, verbose\u001B[38;5;241m=\u001B[39mverbose, pre_dispatch\u001B[38;5;241m=\u001B[39mpre_dispatch)\n\u001B[1;32m--> 309\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    310\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    311\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    312\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    313\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    314\u001B[0m \u001B[43m        \u001B[49m\u001B[43mscorers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    315\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    316\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    317\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    318\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    319\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfit_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    320\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_train_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_train_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    321\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_times\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    322\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_estimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_estimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    323\u001B[0m \u001B[43m        \u001B[49m\u001B[43merror_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merror_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    324\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    325\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mindices\u001B[49m\n\u001B[0;32m    326\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    328\u001B[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001B[0;32m    330\u001B[0m \u001B[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001B[39;00m\n\u001B[0;32m    331\u001B[0m \u001B[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001B[39;00m\n\u001B[0;32m    332\u001B[0m \u001B[38;5;66;03m# the correct key.\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m     60\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[0;32m     61\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     62\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[0;32m     63\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[0;32m     64\u001B[0m )\n\u001B[1;32m---> 65\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\site-packages\\joblib\\parallel.py:1909\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1906\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m   1908\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_managed_backend:\n\u001B[1;32m-> 1909\u001B[0m     n_jobs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_initialize_backend\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1910\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1911\u001B[0m     n_jobs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_effective_n_jobs()\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\site-packages\\joblib\\parallel.py:1359\u001B[0m, in \u001B[0;36mParallel._initialize_backend\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1357\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Build a process or thread pool and return the number of workers\"\"\"\u001B[39;00m\n\u001B[0;32m   1358\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1359\u001B[0m     n_jobs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_backend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfigure\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparallel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1360\u001B[0m \u001B[43m                                     \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_backend_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1361\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39msupports_timeout:\n\u001B[0;32m   1362\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m   1363\u001B[0m             \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mThe backend class \u001B[39m\u001B[38;5;132;01m{!r}\u001B[39;00m\u001B[38;5;124m does not support timeout. \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m   1364\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou have set \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtimeout=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m in Parallel but \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1365\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthe \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m parameter will not be used.\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m   1366\u001B[0m                 \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m,\n\u001B[0;32m   1367\u001B[0m                 \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout))\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\site-packages\\joblib\\_parallel_backends.py:514\u001B[0m, in \u001B[0;36mMultiprocessingBackend.configure\u001B[1;34m(self, n_jobs, parallel, prefer, require, **memmappingpool_args)\u001B[0m\n\u001B[0;32m    512\u001B[0m \u001B[38;5;66;03m# Make sure to free as much memory as possible before forking\u001B[39;00m\n\u001B[0;32m    513\u001B[0m gc\u001B[38;5;241m.\u001B[39mcollect()\n\u001B[1;32m--> 514\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pool \u001B[38;5;241m=\u001B[39m \u001B[43mMemmappingPool\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmemmappingpool_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    515\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparallel \u001B[38;5;241m=\u001B[39m parallel\n\u001B[0;32m    516\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m n_jobs\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\site-packages\\joblib\\pool.py:303\u001B[0m, in \u001B[0;36mMemmappingPool.__init__\u001B[1;34m(self, processes, temp_folder, max_nbytes, mmap_mode, forward_reducers, backward_reducers, verbose, context_id, prewarm, **kwargs)\u001B[0m\n\u001B[0;32m    298\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m context_id \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    299\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcontext_id is deprecated and ignored in joblib\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    300\u001B[0m                   \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m 0.9.4 and will be removed in 0.11\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m    301\u001B[0m                   \u001B[38;5;167;01mDeprecationWarning\u001B[39;00m)\n\u001B[1;32m--> 303\u001B[0m manager \u001B[38;5;241m=\u001B[39m \u001B[43mTemporaryResourcesManager\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtemp_folder\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    304\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_temp_folder_manager \u001B[38;5;241m=\u001B[39m manager\n\u001B[0;32m    306\u001B[0m \u001B[38;5;66;03m# The usage of a temp_folder_resolver over a simple temp_folder is\u001B[39;00m\n\u001B[0;32m    307\u001B[0m \u001B[38;5;66;03m# superfluous for multiprocessing pools, as they don't get reused, see\u001B[39;00m\n\u001B[0;32m    308\u001B[0m \u001B[38;5;66;03m# get_memmapping_executor for more details. We still use it for code\u001B[39;00m\n\u001B[0;32m    309\u001B[0m \u001B[38;5;66;03m# simplicity.\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\site-packages\\joblib\\_memmapping_reducer.py:540\u001B[0m, in \u001B[0;36mTemporaryResourcesManager.__init__\u001B[1;34m(self, temp_folder_root, context_id)\u001B[0m\n\u001B[0;32m    534\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m context_id \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    535\u001B[0m     \u001B[38;5;66;03m# It would be safer to not assign a default context id (less silent\u001B[39;00m\n\u001B[0;32m    536\u001B[0m     \u001B[38;5;66;03m# bugs), but doing this while maintaining backward compatibility\u001B[39;00m\n\u001B[0;32m    537\u001B[0m     \u001B[38;5;66;03m# with the previous, context-unaware version get_memmaping_executor\u001B[39;00m\n\u001B[0;32m    538\u001B[0m     \u001B[38;5;66;03m# exposes too many low-level details.\u001B[39;00m\n\u001B[0;32m    539\u001B[0m     context_id \u001B[38;5;241m=\u001B[39m uuid4()\u001B[38;5;241m.\u001B[39mhex\n\u001B[1;32m--> 540\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_current_context\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcontext_id\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\site-packages\\joblib\\_memmapping_reducer.py:544\u001B[0m, in \u001B[0;36mTemporaryResourcesManager.set_current_context\u001B[1;34m(self, context_id)\u001B[0m\n\u001B[0;32m    542\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mset_current_context\u001B[39m(\u001B[38;5;28mself\u001B[39m, context_id):\n\u001B[0;32m    543\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_current_context_id \u001B[38;5;241m=\u001B[39m context_id\n\u001B[1;32m--> 544\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mregister_new_context\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcontext_id\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\site-packages\\joblib\\_memmapping_reducer.py:566\u001B[0m, in \u001B[0;36mTemporaryResourcesManager.register_new_context\u001B[1;34m(self, context_id)\u001B[0m\n\u001B[0;32m    552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    553\u001B[0m     \u001B[38;5;66;03m# During its lifecycle, one Parallel object can have several\u001B[39;00m\n\u001B[0;32m    554\u001B[0m     \u001B[38;5;66;03m# executors associated to it (for instance, if a loky worker raises\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    560\u001B[0m     \u001B[38;5;66;03m# to the current Manager (and thus specific to its associated\u001B[39;00m\n\u001B[0;32m    561\u001B[0m     \u001B[38;5;66;03m# executor) to the folder name.\u001B[39;00m\n\u001B[0;32m    562\u001B[0m     new_folder_name \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    563\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mjoblib_memmapping_folder_\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m    564\u001B[0m             os\u001B[38;5;241m.\u001B[39mgetpid(), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_id, context_id)\n\u001B[0;32m    565\u001B[0m     )\n\u001B[1;32m--> 566\u001B[0m     new_folder_path, _ \u001B[38;5;241m=\u001B[39m \u001B[43m_get_temp_dir\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    567\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnew_folder_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_temp_folder_root\u001B[49m\n\u001B[0;32m    568\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    569\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mregister_folder_finalizer(new_folder_path, context_id)\n\u001B[0;32m    570\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_cached_temp_folders[context_id] \u001B[38;5;241m=\u001B[39m new_folder_path\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\site-packages\\joblib\\_memmapping_reducer.py:206\u001B[0m, in \u001B[0;36m_get_temp_dir\u001B[1;34m(pool_folder_name, temp_folder)\u001B[0m\n\u001B[0;32m    204\u001B[0m     temp_folder \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39menviron\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mJOBLIB_TEMP_FOLDER\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    205\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m temp_folder \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 206\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexists\u001B[49m\u001B[43m(\u001B[49m\u001B[43mSYSTEM_SHARED_MEM_FS\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(os, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstatvfs\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m    207\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    208\u001B[0m             shm_stats \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mstatvfs(SYSTEM_SHARED_MEM_FS)\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\genericpath.py:19\u001B[0m, in \u001B[0;36mexists\u001B[1;34m(path)\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\u001B[39;00m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 19\u001B[0m     \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mOSError\u001B[39;00m, \u001B[38;5;167;01mValueError\u001B[39;00m):\n\u001B[0;32m     21\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T20:09:00.725543Z",
     "start_time": "2024-12-06T18:06:04.929947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "personal_pipeline = ModelPipeline(data=personal_df, target_column='Personal Loan', test_size=0.2, random_state=42, save_dir='../pipelines/personal_df')\n",
    "personal_pipeline.run_pipeline()"
   ],
   "id": "2415d7d463c5279e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models:   0%|          | 0/4 [00:00<?, ?it/s][I 2024-12-06 21:06:04,939] A new study created in memory with name: no-name-8ceb33e4-e98d-4e55-95ae-e45f0d41be44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Logistic Regression...\n",
      "Starting optimization for Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-06 21:06:09,448] Trial 0 finished with value: 0.0 and parameters: {'C': 1.1119181665445307e-05}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-12-06 21:06:13,645] Trial 1 finished with value: 0.6930760222601825 and parameters: {'C': 3.1056973831422336}. Best is trial 1 with value: 0.6930760222601825.\n",
      "[I 2024-12-06 21:06:17,901] Trial 2 finished with value: 0.6909844868271116 and parameters: {'C': 1.1317839218616637}. Best is trial 1 with value: 0.6930760222601825.\n",
      "[I 2024-12-06 21:06:22,094] Trial 3 finished with value: 0.6929507139841785 and parameters: {'C': 20.935887697602965}. Best is trial 1 with value: 0.6930760222601825.\n",
      "[I 2024-12-06 21:06:26,264] Trial 4 finished with value: 0.0 and parameters: {'C': 0.00037568290870803705}. Best is trial 1 with value: 0.6930760222601825.\n",
      "[I 2024-12-06 21:06:30,413] Trial 5 finished with value: 0.6929507139841785 and parameters: {'C': 18.254798852375977}. Best is trial 1 with value: 0.6930760222601825.\n",
      "[I 2024-12-06 21:06:34,564] Trial 6 finished with value: 0.6929507139841785 and parameters: {'C': 15.499553927024287}. Best is trial 1 with value: 0.6930760222601825.\n",
      "[I 2024-12-06 21:06:38,740] Trial 7 finished with value: 0.6918798550185826 and parameters: {'C': 40.059837933469424}. Best is trial 1 with value: 0.6930760222601825.\n",
      "[I 2024-12-06 21:06:43,330] Trial 8 finished with value: 0.0 and parameters: {'C': 2.968953801176422e-05}. Best is trial 1 with value: 0.6930760222601825.\n",
      "[I 2024-12-06 21:06:47,789] Trial 9 finished with value: 0.07116409573105109 and parameters: {'C': 0.0013464456677041903}. Best is trial 1 with value: 0.6930760222601825.\n",
      "[I 2024-12-06 21:06:51,973] Trial 10 finished with value: 0.6892386097129977 and parameters: {'C': 0.1419707539458274}. Best is trial 1 with value: 0.6930760222601825.\n",
      "[I 2024-12-06 21:06:56,123] Trial 11 finished with value: 0.6920816842033788 and parameters: {'C': 1.0713231830881178}. Best is trial 1 with value: 0.6930760222601825.\n",
      "[I 2024-12-06 21:07:00,292] Trial 12 finished with value: 0.6930760222601825 and parameters: {'C': 1.8904538689349657}. Best is trial 1 with value: 0.6930760222601825.\n",
      "[I 2024-12-06 21:07:04,428] Trial 13 finished with value: 0.6599573836702047 and parameters: {'C': 0.05978147449817905}. Best is trial 1 with value: 0.6930760222601825.\n",
      "[I 2024-12-06 21:07:08,564] Trial 14 finished with value: 0.6930760222601825 and parameters: {'C': 1.603338286046273}. Best is trial 1 with value: 0.6930760222601825.\n",
      "[I 2024-12-06 21:07:12,700] Trial 15 finished with value: 0.4697588571796064 and parameters: {'C': 0.005916255101872798}. Best is trial 1 with value: 0.6930760222601825.\n",
      "[I 2024-12-06 21:07:16,862] Trial 16 finished with value: 0.6963930069930069 and parameters: {'C': 0.37879989038981304}. Best is trial 16 with value: 0.6963930069930069.\n",
      "[I 2024-12-06 21:07:21,130] Trial 17 finished with value: 0.6921271339771339 and parameters: {'C': 0.2521908291186604}. Best is trial 16 with value: 0.6963930069930069.\n",
      "[I 2024-12-06 21:07:25,306] Trial 18 finished with value: 0.57686961537809 and parameters: {'C': 0.012601365726578202}. Best is trial 16 with value: 0.6963930069930069.\n",
      "[I 2024-12-06 21:07:29,482] Trial 19 finished with value: 0.6930760222601825 and parameters: {'C': 6.097529040716389}. Best is trial 16 with value: 0.6963930069930069.\n",
      "[I 2024-12-06 21:07:33,635] Trial 20 finished with value: 0.6918798550185826 and parameters: {'C': 84.69137606041852}. Best is trial 16 with value: 0.6963930069930069.\n",
      "[I 2024-12-06 21:07:37,773] Trial 21 finished with value: 0.6930760222601825 and parameters: {'C': 2.7521861833135386}. Best is trial 16 with value: 0.6963930069930069.\n",
      "[I 2024-12-06 21:07:41,922] Trial 22 finished with value: 0.6952786659077356 and parameters: {'C': 0.4299159074094198}. Best is trial 16 with value: 0.6963930069930069.\n",
      "[I 2024-12-06 21:07:46,090] Trial 23 finished with value: 0.6913452973605192 and parameters: {'C': 0.1360575096165478}. Best is trial 16 with value: 0.6963930069930069.\n",
      "[I 2024-12-06 21:07:50,350] Trial 24 finished with value: 0.6952786659077356 and parameters: {'C': 0.4359853955275477}. Best is trial 16 with value: 0.6963930069930069.\n",
      "[I 2024-12-06 21:07:54,498] Trial 25 finished with value: 0.6963930069930069 and parameters: {'C': 0.3642946529979992}. Best is trial 16 with value: 0.6963930069930069.\n",
      "[I 2024-12-06 21:07:58,647] Trial 26 finished with value: 0.6348860346814311 and parameters: {'C': 0.03572637465290482}. Best is trial 16 with value: 0.6963930069930069.\n",
      "[I 2024-12-06 21:08:02,815] Trial 27 finished with value: 0.5118638706599125 and parameters: {'C': 0.008308189880398869}. Best is trial 16 with value: 0.6963930069930069.\n",
      "[I 2024-12-06 21:08:06,969] Trial 28 finished with value: 0.6952786659077356 and parameters: {'C': 0.4500166889964268}. Best is trial 16 with value: 0.6963930069930069.\n",
      "[I 2024-12-06 21:08:11,128] Trial 29 finished with value: 0.6589489803088602 and parameters: {'C': 0.06277763325901418}. Best is trial 16 with value: 0.6963930069930069.\n",
      "[I 2024-12-06 21:08:15,286] Trial 30 finished with value: 0.6930760222601825 and parameters: {'C': 6.5536051973479985}. Best is trial 16 with value: 0.6963930069930069.\n",
      "[I 2024-12-06 21:08:19,408] Trial 31 finished with value: 0.6942119992410689 and parameters: {'C': 0.4921471271507799}. Best is trial 16 with value: 0.6963930069930069.\n",
      "[I 2024-12-06 21:08:23,651] Trial 32 finished with value: 0.6942119992410689 and parameters: {'C': 0.46879746490884555}. Best is trial 16 with value: 0.6963930069930069.\n",
      "[I 2024-12-06 21:08:27,796] Trial 33 finished with value: 0.6901382532968237 and parameters: {'C': 0.16050211459509092}. Best is trial 16 with value: 0.6963930069930069.\n",
      "[I 2024-12-06 21:08:31,947] Trial 34 finished with value: 0.5986417669320523 and parameters: {'C': 0.016946256947569863}. Best is trial 16 with value: 0.6963930069930069.\n",
      "[I 2024-12-06 21:08:36,119] Trial 35 finished with value: 0.6942119992410689 and parameters: {'C': 0.7942361406581214}. Best is trial 16 with value: 0.6963930069930069.\n",
      "[I 2024-12-06 21:08:40,265] Trial 36 finished with value: 0.35388220783225416 and parameters: {'C': 0.0034977421481612644}. Best is trial 16 with value: 0.6963930069930069.\n",
      "[I 2024-12-06 21:08:44,411] Trial 37 finished with value: 0.6728232514064626 and parameters: {'C': 0.07094885290194418}. Best is trial 16 with value: 0.6963930069930069.\n",
      "[I 2024-12-06 21:08:48,547] Trial 38 finished with value: 0.6930760222601825 and parameters: {'C': 5.304103462970392}. Best is trial 16 with value: 0.6963930069930069.\n",
      "[I 2024-12-06 21:08:52,712] Trial 39 finished with value: 0.6932590237409134 and parameters: {'C': 0.20777714098319855}. Best is trial 16 with value: 0.6963930069930069.\n",
      "[I 2024-12-06 21:08:56,884] Trial 40 finished with value: 0.0 and parameters: {'C': 0.00022025354846080125}. Best is trial 16 with value: 0.6963930069930069.\n",
      "[I 2024-12-06 21:09:01,293] Trial 41 finished with value: 0.6952786659077356 and parameters: {'C': 0.4521223317554154}. Best is trial 16 with value: 0.6963930069930069.\n",
      "[I 2024-12-06 21:09:05,657] Trial 42 finished with value: 0.6942119992410689 and parameters: {'C': 0.814297759722502}. Best is trial 16 with value: 0.6963930069930069.\n",
      "[I 2024-12-06 21:09:09,860] Trial 43 finished with value: 0.6146084776144747 and parameters: {'C': 0.02449037113936139}. Best is trial 16 with value: 0.6963930069930069.\n",
      "[I 2024-12-06 21:09:14,135] Trial 44 finished with value: 0.6942768652607234 and parameters: {'C': 0.28872756661103116}. Best is trial 16 with value: 0.6963930069930069.\n",
      "[I 2024-12-06 21:09:18,343] Trial 45 finished with value: 0.686074336748817 and parameters: {'C': 0.09371595290693166}. Best is trial 16 with value: 0.6963930069930069.\n",
      "[I 2024-12-06 21:09:22,858] Trial 46 finished with value: 0.6930760222601825 and parameters: {'C': 2.7673684371540888}. Best is trial 16 with value: 0.6963930069930069.\n",
      "[I 2024-12-06 21:09:28,164] Trial 47 finished with value: 0.6930760222601825 and parameters: {'C': 1.2218738243095593}. Best is trial 16 with value: 0.6963930069930069.\n",
      "[I 2024-12-06 21:09:32,831] Trial 48 finished with value: 0.6929507139841785 and parameters: {'C': 17.145454697296447}. Best is trial 16 with value: 0.6963930069930069.\n",
      "[I 2024-12-06 21:09:37,228] Trial 49 finished with value: 0.6963930069930069 and parameters: {'C': 0.3612871466028765}. Best is trial 16 with value: 0.6963930069930069.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization completed for Logistic Regression. Best parameters: {'C': 0.37879989038981304}\n",
      "Optimization completed for Logistic Regression. Training...\n",
      "Training Logistic Regression...\n",
      "Model Logistic Regression trained. Evaluating...\n",
      "Using predict_proba for Logistic Regression...\n",
      "Metrics calculated for Logistic Regression. Saving results...\n",
      "Calculating permutation importance for Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models:  25%|██▌       | 1/4 [03:32<10:37, 212.60s/it][I 2024-12-06 21:09:37,539] A new study created in memory with name: no-name-045f40c8-61c0-4ffc-9ebf-10ec7a1f8e54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for Logistic Regression.\n",
      "Model Logistic Regression saved to ../pipelines/personal_df\\Personal Loan\\Logistic Regression\\Logistic Regression_model.pkl.\n",
      "Finished processing Logistic Regression. Metrics: {'accuracy': 0.955, 'f1': 0.7593582887700534, 'precision': 0.8658536585365854, 'recall': 0.6761904761904762, 'roc_auc': 0.9679382814578346}\n",
      "\n",
      "Processing SVM...\n",
      "Starting optimization for SVM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-06 21:09:42,060] Trial 0 finished with value: 0.6531474714824445 and parameters: {'C': 6.94691774394952e-05, 'kernel': 'poly', 'gamma': 6.394637601163642, 'degree': 2}. Best is trial 0 with value: 0.6531474714824445.\n",
      "[I 2024-12-06 21:09:46,858] Trial 1 finished with value: 0.0 and parameters: {'C': 1.25283245298357e-05, 'kernel': 'sigmoid', 'gamma': 0.0007589851772779918}. Best is trial 0 with value: 0.6531474714824445.\n",
      "[I 2024-12-06 21:09:51,700] Trial 2 finished with value: 0.0 and parameters: {'C': 0.0004480199248253714, 'kernel': 'rbf', 'gamma': 9.829445779912104e-05}. Best is trial 0 with value: 0.6531474714824445.\n",
      "[I 2024-12-06 21:09:56,382] Trial 3 finished with value: 0.6881323173405285 and parameters: {'C': 4.559700835344471, 'kernel': 'linear'}. Best is trial 3 with value: 0.6881323173405285.\n",
      "[I 2024-12-06 21:10:00,592] Trial 4 finished with value: 0.0 and parameters: {'C': 0.0009103402507249163, 'kernel': 'poly', 'gamma': 0.017075552083526426, 'degree': 2}. Best is trial 3 with value: 0.6881323173405285.\n",
      "[I 2024-12-06 21:10:04,829] Trial 5 finished with value: 0.6860751744833857 and parameters: {'C': 5.329244110114893, 'kernel': 'linear'}. Best is trial 3 with value: 0.6881323173405285.\n",
      "[I 2024-12-06 21:10:09,029] Trial 6 finished with value: 0.6914484052532833 and parameters: {'C': 1.1517398694072316, 'kernel': 'linear'}. Best is trial 6 with value: 0.6914484052532833.\n",
      "[I 2024-12-06 21:10:13,350] Trial 7 finished with value: 0.0 and parameters: {'C': 0.000273547953158285, 'kernel': 'linear'}. Best is trial 6 with value: 0.6914484052532833.\n",
      "[I 2024-12-06 21:10:17,540] Trial 8 finished with value: 0.7133838328611428 and parameters: {'C': 9.30472190086679, 'kernel': 'poly', 'gamma': 0.07273702093057385, 'degree': 2}. Best is trial 8 with value: 0.7133838328611428.\n",
      "[I 2024-12-06 21:10:21,788] Trial 9 finished with value: 0.8273512395070315 and parameters: {'C': 23.05941625489928, 'kernel': 'rbf', 'gamma': 0.20252983586349182}. Best is trial 9 with value: 0.8273512395070315.\n",
      "[I 2024-12-06 21:10:26,367] Trial 10 finished with value: 0.030905803057701797 and parameters: {'C': 96.05841205046097, 'kernel': 'rbf', 'gamma': 2.0105134090444685}. Best is trial 9 with value: 0.8273512395070315.\n",
      "[I 2024-12-06 21:10:30,590] Trial 11 finished with value: 0.6583802180849336 and parameters: {'C': 0.05299267276508695, 'kernel': 'poly', 'gamma': 0.10625798135328111, 'degree': 5}. Best is trial 9 with value: 0.8273512395070315.\n",
      "[I 2024-12-06 21:10:34,782] Trial 12 finished with value: 0.8366756744815662 and parameters: {'C': 97.55159420107013, 'kernel': 'rbf', 'gamma': 0.1455347148583473}. Best is trial 12 with value: 0.8366756744815662.\n",
      "[I 2024-12-06 21:10:39,013] Trial 13 finished with value: 0.7888467885420072 and parameters: {'C': 58.24091801772716, 'kernel': 'rbf', 'gamma': 0.2813497126516178}. Best is trial 12 with value: 0.8366756744815662.\n",
      "[I 2024-12-06 21:10:43,235] Trial 14 finished with value: 0.10552556913316406 and parameters: {'C': 0.3261970373036173, 'kernel': 'rbf', 'gamma': 0.0026604255098458163}. Best is trial 12 with value: 0.8366756744815662.\n",
      "[I 2024-12-06 21:10:47,578] Trial 15 finished with value: 0.0 and parameters: {'C': 0.007734934562024991, 'kernel': 'rbf', 'gamma': 0.7101383046822344}. Best is trial 12 with value: 0.8366756744815662.\n",
      "[I 2024-12-06 21:10:51,797] Trial 16 finished with value: 0.5000116806230432 and parameters: {'C': 0.17921418564267716, 'kernel': 'rbf', 'gamma': 0.015904150056682876}. Best is trial 12 with value: 0.8366756744815662.\n",
      "[I 2024-12-06 21:10:56,017] Trial 17 finished with value: 0.0 and parameters: {'C': 18.63780212466064, 'kernel': 'sigmoid', 'gamma': 1.4883686826782773e-05}. Best is trial 12 with value: 0.8366756744815662.\n",
      "[I 2024-12-06 21:11:00,221] Trial 18 finished with value: 0.822010871804278 and parameters: {'C': 1.2221440175391984, 'kernel': 'rbf', 'gamma': 0.055233296539625866}. Best is trial 12 with value: 0.8366756744815662.\n",
      "[I 2024-12-06 21:11:04,778] Trial 19 finished with value: 0.1796151053013798 and parameters: {'C': 25.7520200319272, 'kernel': 'rbf', 'gamma': 1.1966219778842142}. Best is trial 12 with value: 0.8366756744815662.\n",
      "[I 2024-12-06 21:11:09,209] Trial 20 finished with value: 0.4793591859185919 and parameters: {'C': 1.150462262575547, 'kernel': 'sigmoid', 'gamma': 0.0031089587046283615}. Best is trial 12 with value: 0.8366756744815662.\n",
      "[I 2024-12-06 21:11:13,895] Trial 21 finished with value: 0.8343750723913768 and parameters: {'C': 1.5357767311923667, 'kernel': 'rbf', 'gamma': 0.07032336453309546}. Best is trial 12 with value: 0.8366756744815662.\n",
      "[I 2024-12-06 21:11:18,527] Trial 22 finished with value: 0.7428949742537085 and parameters: {'C': 87.88825247687403, 'kernel': 'rbf', 'gamma': 0.34903190978522386}. Best is trial 12 with value: 0.8366756744815662.\n",
      "[I 2024-12-06 21:11:22,754] Trial 23 finished with value: 0.8706961394244098 and parameters: {'C': 3.566474394873751, 'kernel': 'rbf', 'gamma': 0.09196110052351981}. Best is trial 23 with value: 0.8706961394244098.\n",
      "[I 2024-12-06 21:11:27,048] Trial 24 finished with value: 0.0 and parameters: {'C': 0.018555004017029534, 'kernel': 'rbf', 'gamma': 0.04231480978889253}. Best is trial 23 with value: 0.8706961394244098.\n",
      "[I 2024-12-06 21:11:31,262] Trial 25 finished with value: 0.7464339363406746 and parameters: {'C': 3.020714332381051, 'kernel': 'rbf', 'gamma': 0.0074219693864798755}. Best is trial 23 with value: 0.8706961394244098.\n",
      "[I 2024-12-06 21:11:35,836] Trial 26 finished with value: 0.0 and parameters: {'C': 0.2628367656397961, 'kernel': 'rbf', 'gamma': 7.295788520033213}. Best is trial 23 with value: 0.8706961394244098.\n",
      "[I 2024-12-06 21:11:40,057] Trial 27 finished with value: 0.0 and parameters: {'C': 0.06000172953194004, 'kernel': 'rbf', 'gamma': 0.0005292100235828557}. Best is trial 23 with value: 0.8706961394244098.\n",
      "[I 2024-12-06 21:11:44,271] Trial 28 finished with value: 0.0 and parameters: {'C': 0.005551238616589024, 'kernel': 'sigmoid', 'gamma': 0.03342010885253748}. Best is trial 23 with value: 0.8706961394244098.\n",
      "[I 2024-12-06 21:11:48,485] Trial 29 finished with value: 0.7811465400083355 and parameters: {'C': 1.7475024596404256, 'kernel': 'poly', 'gamma': 0.1774031425202967, 'degree': 5}. Best is trial 23 with value: 0.8706961394244098.\n",
      "[I 2024-12-06 21:11:53,077] Trial 30 finished with value: 0.01551781551781552 and parameters: {'C': 11.17362369783306, 'kernel': 'rbf', 'gamma': 2.3010222057446326}. Best is trial 23 with value: 0.8706961394244098.\n",
      "[I 2024-12-06 21:11:57,525] Trial 31 finished with value: 0.5369478750454773 and parameters: {'C': 18.920756116747306, 'kernel': 'rbf', 'gamma': 0.5620066180898552}. Best is trial 23 with value: 0.8706961394244098.\n",
      "[I 2024-12-06 21:12:01,776] Trial 32 finished with value: 0.8338363451913718 and parameters: {'C': 29.838397674171915, 'kernel': 'rbf', 'gamma': 0.15621401834443363}. Best is trial 23 with value: 0.8706961394244098.\n",
      "[I 2024-12-06 21:12:05,980] Trial 33 finished with value: 0.8396655904003438 and parameters: {'C': 42.00946528449789, 'kernel': 'rbf', 'gamma': 0.1331544097563967}. Best is trial 23 with value: 0.8706961394244098.\n",
      "[I 2024-12-06 21:12:10,195] Trial 34 finished with value: 0.0 and parameters: {'C': 1.307865087573303e-05, 'kernel': 'rbf', 'gamma': 0.00640910590777682}. Best is trial 23 with value: 0.8706961394244098.\n",
      "[I 2024-12-06 21:12:14,412] Trial 35 finished with value: 0.5966284790195241 and parameters: {'C': 0.5297001004759228, 'kernel': 'sigmoid', 'gamma': 0.01863080183555316}. Best is trial 23 with value: 0.8706961394244098.\n",
      "[I 2024-12-06 21:12:18,630] Trial 36 finished with value: 0.8694257011320555 and parameters: {'C': 5.735193754460052, 'kernel': 'rbf', 'gamma': 0.08286917969184024}. Best is trial 23 with value: 0.8706961394244098.\n",
      "[I 2024-12-06 21:12:22,891] Trial 37 finished with value: 0.6860751744833857 and parameters: {'C': 7.586771822437755, 'kernel': 'linear'}. Best is trial 23 with value: 0.8706961394244098.\n",
      "[I 2024-12-06 21:12:27,549] Trial 38 finished with value: 0.010323010323010324 and parameters: {'C': 49.324690266382255, 'kernel': 'rbf', 'gamma': 2.816392211876572}. Best is trial 23 with value: 0.8706961394244098.\n",
      "[I 2024-12-06 21:12:31,780] Trial 39 finished with value: 0.7504101073637498 and parameters: {'C': 4.090889895255181, 'kernel': 'poly', 'gamma': 0.8488288759409731, 'degree': 4}. Best is trial 23 with value: 0.8706961394244098.\n",
      "[I 2024-12-06 21:12:35,981] Trial 40 finished with value: 0.8672146837716701 and parameters: {'C': 9.262429952463187, 'kernel': 'rbf', 'gamma': 0.028104197418347996}. Best is trial 23 with value: 0.8706961394244098.\n",
      "[I 2024-12-06 21:12:40,188] Trial 41 finished with value: 0.8636353621367497 and parameters: {'C': 10.488259108500104, 'kernel': 'rbf', 'gamma': 0.02187865590156725}. Best is trial 23 with value: 0.8706961394244098.\n",
      "[I 2024-12-06 21:12:44,420] Trial 42 finished with value: 0.6881323173405285 and parameters: {'C': 3.4420263351404388, 'kernel': 'linear'}. Best is trial 23 with value: 0.8706961394244098.\n",
      "[I 2024-12-06 21:12:48,627] Trial 43 finished with value: 0.8748305739249045 and parameters: {'C': 14.255349278148298, 'kernel': 'rbf', 'gamma': 0.03248729569247875}. Best is trial 43 with value: 0.8748305739249045.\n",
      "[I 2024-12-06 21:12:52,846] Trial 44 finished with value: 0.865036749456119 and parameters: {'C': 8.503798925746088, 'kernel': 'rbf', 'gamma': 0.027770934587256026}. Best is trial 43 with value: 0.8748305739249045.\n",
      "[I 2024-12-06 21:12:57,037] Trial 45 finished with value: 0.4812403540809106 and parameters: {'C': 0.49338016289460235, 'kernel': 'rbf', 'gamma': 0.004302635867414039}. Best is trial 43 with value: 0.8748305739249045.\n",
      "[I 2024-12-06 21:13:01,336] Trial 46 finished with value: 0.8186780286601183 and parameters: {'C': 5.872751681749588, 'kernel': 'rbf', 'gamma': 0.012285283235793618}. Best is trial 43 with value: 0.8748305739249045.\n",
      "[I 2024-12-06 21:13:05,557] Trial 47 finished with value: 0.6892751744833857 and parameters: {'C': 2.523387402205492, 'kernel': 'linear'}. Best is trial 43 with value: 0.8748305739249045.\n",
      "[I 2024-12-06 21:13:09,733] Trial 48 finished with value: 0.0 and parameters: {'C': 0.1089048832405477, 'kernel': 'poly', 'gamma': 0.001608996837485875, 'degree': 3}. Best is trial 43 with value: 0.8748305739249045.\n",
      "[I 2024-12-06 21:13:13,933] Trial 49 finished with value: 0.8748305739249045 and parameters: {'C': 12.984086413124546, 'kernel': 'rbf', 'gamma': 0.03266352302071416}. Best is trial 43 with value: 0.8748305739249045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization completed for SVM. Best parameters: {'C': 14.255349278148298, 'kernel': 'rbf', 'gamma': 0.03248729569247875}\n",
      "Optimization completed for SVM. Training...\n",
      "Training SVM...\n",
      "Model SVM trained. Evaluating...\n",
      "Using decision_function for SVM...\n",
      "Metrics calculated for SVM. Saving results...\n",
      "Calculating permutation importance for SVM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models:  50%|█████     | 2/4 [07:11<07:12, 216.33s/it][I 2024-12-06 21:13:16,474] A new study created in memory with name: no-name-2fcb6c86-9578-469e-b413-993fdf5c25c2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for SVM.\n",
      "Model SVM saved to ../pipelines/personal_df\\Personal Loan\\SVM\\SVM_model.pkl.\n",
      "Finished processing SVM. Metrics: {'accuracy': 0.987, 'f1': 0.9353233830845771, 'precision': 0.9791666666666666, 'recall': 0.8952380952380953, 'roc_auc': 0.9949773876030858}\n",
      "\n",
      "Processing Random Forest...\n",
      "Starting optimization for Random Forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:13:22,947] Trial 0 finished with value: 0.902421803548564 and parameters: {'n_estimators': 625, 'max_depth': 14, 'min_samples_split': 8, 'min_samples_leaf': 7, 'max_features': None}. Best is trial 0 with value: 0.902421803548564.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:13:30,479] Trial 1 finished with value: 0.9076982810329655 and parameters: {'n_estimators': 1350, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 1 with value: 0.9076982810329655.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:13:37,279] Trial 2 finished with value: 0.9011249443793645 and parameters: {'n_estimators': 650, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 7, 'max_features': None}. Best is trial 1 with value: 0.9076982810329655.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:13:43,205] Trial 3 finished with value: 0.8972578458971953 and parameters: {'n_estimators': 650, 'max_depth': 14, 'min_samples_split': 10, 'min_samples_leaf': 6, 'max_features': 'sqrt'}. Best is trial 1 with value: 0.9076982810329655.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:13:49,894] Trial 4 finished with value: 0.9035673249282841 and parameters: {'n_estimators': 950, 'max_depth': 12, 'min_samples_split': 6, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 1 with value: 0.9076982810329655.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:13:55,052] Trial 5 finished with value: 0.8574107727195474 and parameters: {'n_estimators': 375, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 8, 'max_features': 'sqrt'}. Best is trial 1 with value: 0.9076982810329655.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:14:01,211] Trial 6 finished with value: 0.9048393507858588 and parameters: {'n_estimators': 725, 'max_depth': 16, 'min_samples_split': 9, 'min_samples_leaf': 5, 'max_features': 'log2'}. Best is trial 1 with value: 0.9076982810329655.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:14:06,210] Trial 7 finished with value: 0.16544049537461902 and parameters: {'n_estimators': 450, 'max_depth': 2, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 1 with value: 0.9076982810329655.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:14:13,204] Trial 8 finished with value: 0.9048393507858588 and parameters: {'n_estimators': 1075, 'max_depth': 14, 'min_samples_split': 4, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 1 with value: 0.9076982810329655.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:14:20,577] Trial 9 finished with value: 0.8872777031823353 and parameters: {'n_estimators': 1300, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 10, 'max_features': 'sqrt'}. Best is trial 1 with value: 0.9076982810329655.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:14:25,036] Trial 10 finished with value: 0.8834725600997941 and parameters: {'n_estimators': 50, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 1 with value: 0.9076982810329655.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:14:32,768] Trial 11 finished with value: 0.9108269942787676 and parameters: {'n_estimators': 1375, 'max_depth': 20, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 11 with value: 0.9108269942787676.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:14:40,598] Trial 12 finished with value: 0.9076982810329655 and parameters: {'n_estimators': 1475, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 11 with value: 0.9108269942787676.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:14:48,047] Trial 13 finished with value: 0.9111141166674743 and parameters: {'n_estimators': 1225, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 13 with value: 0.9111141166674743.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:14:55,186] Trial 14 finished with value: 0.9095132626553706 and parameters: {'n_estimators': 1125, 'max_depth': 20, 'min_samples_split': 7, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 13 with value: 0.9111141166674743.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:15:02,551] Trial 15 finished with value: 0.9050915641215058 and parameters: {'n_estimators': 1200, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 13 with value: 0.9111141166674743.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:15:12,436] Trial 16 finished with value: 0.9123174227756184 and parameters: {'n_estimators': 1500, 'max_depth': 18, 'min_samples_split': 8, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 16 with value: 0.9123174227756184.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:15:22,235] Trial 17 finished with value: 0.9110500665180468 and parameters: {'n_estimators': 1500, 'max_depth': 18, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 16 with value: 0.9123174227756184.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:15:30,076] Trial 18 finished with value: 0.9109621604834259 and parameters: {'n_estimators': 950, 'max_depth': 16, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 16 with value: 0.9123174227756184.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:15:37,927] Trial 19 finished with value: 0.9052479269012099 and parameters: {'n_estimators': 950, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 16 with value: 0.9123174227756184.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:15:46,520] Trial 20 finished with value: 0.9072062553850863 and parameters: {'n_estimators': 1200, 'max_depth': 16, 'min_samples_split': 8, 'min_samples_leaf': 4, 'max_features': None}. Best is trial 16 with value: 0.9123174227756184.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:15:56,070] Trial 21 finished with value: 0.9123174227756184 and parameters: {'n_estimators': 1450, 'max_depth': 18, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 16 with value: 0.9123174227756184.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:16:05,761] Trial 22 finished with value: 0.9083289780826727 and parameters: {'n_estimators': 1475, 'max_depth': 18, 'min_samples_split': 9, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 16 with value: 0.9123174227756184.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:16:14,884] Trial 23 finished with value: 0.9077973941767045 and parameters: {'n_estimators': 1300, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 16 with value: 0.9123174227756184.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:16:24,110] Trial 24 finished with value: 0.9121346172373318 and parameters: {'n_estimators': 1375, 'max_depth': 16, 'min_samples_split': 7, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 16 with value: 0.9123174227756184.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:16:34,034] Trial 25 finished with value: 0.9083289780826727 and parameters: {'n_estimators': 1500, 'max_depth': 16, 'min_samples_split': 9, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 16 with value: 0.9123174227756184.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:16:42,236] Trial 26 finished with value: 0.9056279914753869 and parameters: {'n_estimators': 1050, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_features': None}. Best is trial 16 with value: 0.9123174227756184.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:16:53,323] Trial 27 finished with value: 0.9108436391195012 and parameters: {'n_estimators': 1375, 'max_depth': 14, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 16 with value: 0.9123174227756184.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:17:03,470] Trial 28 finished with value: 0.9093110720696927 and parameters: {'n_estimators': 1400, 'max_depth': 18, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 16 with value: 0.9123174227756184.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:17:11,837] Trial 29 finished with value: 0.910532659558886 and parameters: {'n_estimators': 825, 'max_depth': 14, 'min_samples_split': 9, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 16 with value: 0.9123174227756184.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:17:25,106] Trial 30 finished with value: 0.9031533083392439 and parameters: {'n_estimators': 1250, 'max_depth': 16, 'min_samples_split': 7, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 16 with value: 0.9123174227756184.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:17:37,324] Trial 31 finished with value: 0.907484405131321 and parameters: {'n_estimators': 1175, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 16 with value: 0.9123174227756184.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:17:53,740] Trial 32 finished with value: 0.9089980830243093 and parameters: {'n_estimators': 1400, 'max_depth': 18, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 16 with value: 0.9123174227756184.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:18:14,296] Trial 33 finished with value: 0.9059403130138062 and parameters: {'n_estimators': 1300, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 4, 'max_features': None}. Best is trial 16 with value: 0.9123174227756184.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:18:30,942] Trial 34 finished with value: 0.9004445708519098 and parameters: {'n_estimators': 1400, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 6, 'max_features': 'log2'}. Best is trial 16 with value: 0.9123174227756184.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:18:47,585] Trial 35 finished with value: 0.9062993564222213 and parameters: {'n_estimators': 1300, 'max_depth': 16, 'min_samples_split': 7, 'min_samples_leaf': 8, 'max_features': None}. Best is trial 16 with value: 0.9123174227756184.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:19:03,832] Trial 36 finished with value: 0.9154084139195181 and parameters: {'n_estimators': 1025, 'max_depth': 12, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 36 with value: 0.9154084139195181.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:19:17,235] Trial 37 finished with value: 0.9154084139195181 and parameters: {'n_estimators': 875, 'max_depth': 12, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 36 with value: 0.9154084139195181.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:19:29,308] Trial 38 finished with value: 0.9110055391381635 and parameters: {'n_estimators': 850, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 36 with value: 0.9154084139195181.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:19:40,752] Trial 39 finished with value: 0.9156514788169463 and parameters: {'n_estimators': 525, 'max_depth': 12, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 39 with value: 0.9156514788169463.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:19:51,112] Trial 40 finished with value: 0.9138027419353663 and parameters: {'n_estimators': 525, 'max_depth': 12, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 39 with value: 0.9156514788169463.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:20:04,019] Trial 41 finished with value: 0.9138027419353663 and parameters: {'n_estimators': 525, 'max_depth': 12, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 39 with value: 0.9156514788169463.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:20:16,753] Trial 42 finished with value: 0.9138027419353663 and parameters: {'n_estimators': 525, 'max_depth': 12, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 39 with value: 0.9156514788169463.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:20:27,533] Trial 43 finished with value: 0.9156309238323628 and parameters: {'n_estimators': 550, 'max_depth': 12, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 39 with value: 0.9156514788169463.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:20:37,582] Trial 44 finished with value: 0.9139310180759249 and parameters: {'n_estimators': 375, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 39 with value: 0.9156514788169463.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:20:47,006] Trial 45 finished with value: 0.89725378186819 and parameters: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 7, 'max_features': 'sqrt'}. Best is trial 39 with value: 0.9156514788169463.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:20:56,617] Trial 46 finished with value: 0.9095084446833226 and parameters: {'n_estimators': 275, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 39 with value: 0.9156514788169463.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:21:07,595] Trial 47 finished with value: 0.8895371788545464 and parameters: {'n_estimators': 725, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 9, 'max_features': 'sqrt'}. Best is trial 39 with value: 0.9156514788169463.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:21:18,848] Trial 48 finished with value: 0.9042321361450041 and parameters: {'n_estimators': 600, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 39 with value: 0.9156514788169463.\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:174: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 50, 1500, 25)\n",
      "C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py:175: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 2, 20, 2)\n",
      "[I 2024-12-06 21:21:28,470] Trial 49 finished with value: 0.915474429309671 and parameters: {'n_estimators': 375, 'max_depth': 14, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 39 with value: 0.9156514788169463.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization completed for Random Forest. Best parameters: {'n_estimators': 525, 'max_depth': 12, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Optimization completed for Random Forest. Training...\n",
      "Training Random Forest...\n",
      "Model Random Forest trained. Evaluating...\n",
      "Using predict_proba for Random Forest...\n",
      "Metrics calculated for Random Forest. Saving results...\n",
      "Extracting feature importance for Random Forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models:  75%|███████▌  | 3/4 [15:26<05:43, 343.36s/it][I 2024-12-06 21:21:31,015] A new study created in memory with name: no-name-7c09f732-f5fb-49bb-8a41-1bc4d3e447a3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for Random Forest.\n",
      "Model Random Forest saved to ../pipelines/personal_df\\Personal Loan\\Random Forest\\Random Forest_model.pkl.\n",
      "Finished processing Random Forest. Metrics: {'accuracy': 0.989, 'f1': 0.9458128078817734, 'precision': 0.9795918367346939, 'recall': 0.9142857142857143, 'roc_auc': 0.9987017823889333}\n",
      "\n",
      "Processing Boosting...\n",
      "Starting optimization for Boosting...\n",
      "Optimization running without parallelization for Boosting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-06 21:22:45,472] Trial 0 finished with value: 0.8887882166885145 and parameters: {'learning_rate': 0.0010147374618939041, 'depth': 8, 'iterations': 275}. Best is trial 0 with value: 0.8887882166885145.\n",
      "[I 2024-12-06 21:37:03,139] Trial 1 finished with value: 0.9171221788658471 and parameters: {'learning_rate': 0.01362383936923281, 'depth': 9, 'iterations': 1850}. Best is trial 1 with value: 0.9171221788658471.\n",
      "[I 2024-12-06 21:38:04,839] Trial 2 finished with value: 0.9193710780903501 and parameters: {'learning_rate': 0.008350769026173054, 'depth': 6, 'iterations': 525}. Best is trial 2 with value: 0.9193710780903501.\n",
      "[I 2024-12-06 21:38:13,681] Trial 3 finished with value: 0.9037719231420661 and parameters: {'learning_rate': 0.00586675150046469, 'depth': 5, 'iterations': 350}. Best is trial 2 with value: 0.9193710780903501.\n",
      "[I 2024-12-06 21:41:18,249] Trial 4 finished with value: 0.9047823729301495 and parameters: {'learning_rate': 0.002430438068786175, 'depth': 4, 'iterations': 1750}. Best is trial 2 with value: 0.9193710780903501.\n",
      "[I 2024-12-06 22:03:10,363] Trial 5 finished with value: 0.9199590582984711 and parameters: {'learning_rate': 0.07263591791193909, 'depth': 10, 'iterations': 1425}. Best is trial 5 with value: 0.9199590582984711.\n",
      "[I 2024-12-06 22:21:08,930] Trial 6 finished with value: 0.9202443240635585 and parameters: {'learning_rate': 0.003954287815387494, 'depth': 10, 'iterations': 1800}. Best is trial 6 with value: 0.9202443240635585.\n",
      "[I 2024-12-06 22:21:20,203] Trial 7 finished with value: 0.8889403891906238 and parameters: {'learning_rate': 0.0016678302911242128, 'depth': 7, 'iterations': 350}. Best is trial 6 with value: 0.9202443240635585.\n",
      "[I 2024-12-06 22:24:26,799] Trial 8 finished with value: 0.8981776508339505 and parameters: {'learning_rate': 0.0015028945608311847, 'depth': 10, 'iterations': 775}. Best is trial 6 with value: 0.9202443240635585.\n",
      "[I 2024-12-06 22:25:46,862] Trial 9 finished with value: 0.9182646125749574 and parameters: {'learning_rate': 0.019044960469475274, 'depth': 4, 'iterations': 750}. Best is trial 6 with value: 0.9202443240635585.\n",
      "[W 2024-12-06 23:08:58,525] Trial 10 failed with parameters: {'learning_rate': 0.03668248721989245, 'depth': 12, 'iterations': 1325} because of the following error: KeyboardInterrupt('').\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mitay\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py\", line 267, in objective\n",
      "    return self.objective_boosting(trial)\n",
      "  File \"C:\\Users\\mitay\\AppData\\Local\\Temp\\ipykernel_15012\\603090270.py\", line 209, in objective_boosting\n",
      "    score = cross_val_score(model, self.X_train_scaled, self.y_train, cv=5, scoring='f1').mean()\n",
      "  File \"C:\\Users\\mitay\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 562, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "  File \"C:\\Users\\mitay\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 214, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mitay\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 309, in cross_validate\n",
      "    results = parallel(\n",
      "  File \"C:\\Users\\mitay\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 65, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"C:\\Users\\mitay\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"C:\\Users\\mitay\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mitay\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 127, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\mitay\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mitay\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\site-packages\\catboost\\core.py\", line 5245, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"C:\\Users\\mitay\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\site-packages\\catboost\\core.py\", line 2410, in _fit\n",
      "    self._train(\n",
      "  File \"C:\\Users\\mitay\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\site-packages\\catboost\\core.py\", line 1790, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 5017, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 5066, in _catboost._CatBoost._train\n",
      "KeyboardInterrupt\n",
      "[W 2024-12-06 23:08:58,581] Trial 10 failed with value None.\n",
      "Models:  75%|███████▌  | 3/4 [2:02:53<40:57, 2457.88s/it]\n",
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x0000022118D51D90>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mitay\\AppData\\Local\\anaconda3\\envs\\course_work\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cebf53ee38a365e4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7a053b96bfb8204f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
